{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297ef6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aada36e",
   "metadata": {},
   "source": [
    "## Implementing Bagging from stratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d9862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "X_train , X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Parameters\n",
    "n_estimators = 10\n",
    "n_samples = int(0.8 * len(X_train))\n",
    "models = []\n",
    "\n",
    "# Train multiple models on different bootstrap samples\n",
    "for i in range(n_estimators):\n",
    "    X_sample, y_sample = resample(X_train, y_train, n_samples=n_samples, replace=True, random_state=i)\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_sample, y_sample)\n",
    "    models.append(model)\n",
    "\n",
    "# Make predictions (majority voting)\n",
    "from scipy.stats import mode\n",
    "\n",
    "predictions = np.array([model.predict(X_test) for model in models])\n",
    "final_prediction, _ = mode(predictions, axis=0)\n",
    "\n",
    "print(\"Bagging Accuracy:\\n\", classification_report(y_test, final_prediction.ravel()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aad48d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6278c92",
   "metadata": {},
   "source": [
    "The results above clearly demonstrate that bagging significantly reduces test error and enhances model performance. By aggregating predictions from multiple base estimators trained on different bootstrap samples, bagging increases the robustness and generalization ability of the model, leading to improved accuracy and more reliable predictions on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5cdf20",
   "metadata": {},
   "source": [
    "## Baging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99b4fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X_moons, y_moons = make_moons(n_samples=1500, noise=0.3, random_state=42)\n",
    "\n",
    "X_train , X_test , y_train, y_test = train_test_split(X_moons, y_moons\n",
    "                                                      , test_size=0.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abf52e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=500,\n",
    "    bootstrap=True, \n",
    "    n_jobs=-1\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a3ff2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       148\n",
      "           1       0.93      0.91      0.92       152\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.92      0.92      0.92       300\n",
      "weighted avg       0.92      0.92      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570b3b89",
   "metadata": {},
   "source": [
    "##  Out-of-Bag Evaluation\n",
    "\n",
    "With bagging, some instances may be sampled several times for any given predictor,\n",
    " while others may not be sampled at all. By default a BaggingClassifier samples m\n",
    " training instances with replacement (bootstrap=True), where m is the size of the\n",
    " training set. This means that only about 63% of the training instances are sampled on\n",
    " average for each predictor.6 The remaining 37% of the training instances that are not\n",
    " sampled are called out-of-bag (oob) instances. Note that they are not the same 37%\n",
    " for all predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df9dc9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8841666666666667"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=500,\n",
    "    bootstrap=True, \n",
    "    n_jobs=-1,\n",
    "    oob_score=True,\n",
    "    bootstrap_features=True\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3aee16",
   "metadata": {},
   "source": [
    " According to this oob evaluation, this BaggingClassifier is likely to achieve about\n",
    " 89.08% accuracy on the test set. Let's verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33f2a037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       148\n",
      "           1       0.93      0.89      0.91       152\n",
      "\n",
      "    accuracy                           0.91       300\n",
      "   macro avg       0.91      0.91      0.91       300\n",
      "weighted avg       0.91      0.91      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, bag_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a0b9cc",
   "metadata": {},
   "source": [
    "91% Accuracy that's close enought."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e1e19",
   "metadata": {},
   "source": [
    "## Random Patches and Random Subpatches\n",
    "\n",
    " - Random Patches: sampling both training instance and features\n",
    " - Random Subpatches: Keeping all training instances (i.e., bootstrap=False and max_sam\n",
    "    ples=1.0) but sampling features (i.e., bootstrap_features=True and/or max_fea\n",
    "    tures smaller than 1.0) is called the Random Subspaces method.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae5ca164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91       148\n",
      "           1       0.92      0.89      0.91       152\n",
      "\n",
      "    accuracy                           0.91       300\n",
      "   macro avg       0.91      0.91      0.91       300\n",
      "weighted avg       0.91      0.91      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Patches\n",
    "bag_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=500,\n",
    "    bootstrap=True, \n",
    "    n_jobs=-1,\n",
    "    oob_score=True,\n",
    "    bootstrap_features=True\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, bag_clf.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97e0db72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       148\n",
      "           1       0.89      0.88      0.88       152\n",
      "\n",
      "    accuracy                           0.88       300\n",
      "   macro avg       0.88      0.88      0.88       300\n",
      "weighted avg       0.88      0.88      0.88       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random subpatches\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=500,\n",
    "    bootstrap=False,\n",
    "    n_jobs=-1,\n",
    "    bootstrap_features=True\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, bag_clf.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075b9ffb",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    " : It's obvious that random patches imporves the model performance better than random subpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1bf4310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       148\n",
      "           1       0.96      0.91      0.93       152\n",
      "\n",
      "    accuracy                           0.93       300\n",
      "   macro avg       0.93      0.93      0.93       300\n",
      "weighted avg       0.93      0.93      0.93       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier: an essemble extension  of decision tree 4\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, # NORMALL EQUALS TO TRAIN SIZE\n",
    "                                 max_leaf_nodes=16,\n",
    "                                 n_jobs=-1, \n",
    "                                 max_samples=1.0                              \n",
    "                                 )\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b73dda",
   "metadata": {},
   "source": [
    "-  The BaggingClassifier class remains useful if you want a bag of something other than Decision Trees.\n",
    "- There are a few notable exceptions: splitter is absent (forced to \"random\"), presort is absent (forced to\n",
    " False), max_samples is absent (forced to 1.0), and base_estimator is absent (forced to DecisionTreeClassi\n",
    " fier with the provided hyperparameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da81d58d",
   "metadata": {},
   "source": [
    "> **Note:**  \n",
    "> It is difficult to predict in advance whether a `RandomForestClassifier` will outperform an `ExtraTreesClassifier`.  \n",
    "> \n",
    "> The best practice is to try both algorithms and compare their performance using cross-validation, while tuning their hyperparameters (e.g., via grid search).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247d6da",
   "metadata": {},
   "source": [
    "## Random Forest for Feature Selection\n",
    "\n",
    "Random Forests are powerful tools not only for classification and regression tasks but also for identifying the most important features in your dataset. By evaluating feature importances, Random Forests provide valuable insights into which features contribute most to the predictive performance of the model.\n",
    "\n",
    "<div style=\"background: black; border-left: 4px solid #007acc; padding: 1em; margin: 1em 0; border-radius: 4px;\">\n",
    "<strong>Key Benefits:</strong>\n",
    "<ul>\n",
    "    <li><strong>Automatic Feature Ranking:</strong> Random Forests assign an importance score to each feature, helping you focus on the most relevant variables.</li>\n",
    "    <li><strong>Dimensionality Reduction:</strong> By selecting only the top features, you can simplify your models and potentially improve generalization.</li>\n",
    "    <li><strong>Interpretability:</strong> Feature importances provide transparency into model decisions, supporting explainable AI initiatives.</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "> 💡 <strong>Tip:</strong> Use the <code>feature_importances_</code> attribute of a trained <code>RandomForestClassifier</code> to access and visualize feature importances for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d75677e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.0933684479691592\n",
      "sepal width (cm) 0.023038342946713693\n",
      "petal length (cm) 0.43033229650352717\n",
      "petal width (cm) 0.45326091258059986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5773aa7f",
   "metadata": {},
   "source": [
    "**It seems that the most important features are:**\n",
    "\n",
    "- **Petal length:** 44%\n",
    "- **Petal width:** 42%\n",
    "- **Sepal length:** 11%\n",
    "- **Sepal width:** 2%\n",
    "\n",
    "<span style=\"color:#007acc\"><strong>Conclusion:</strong></span>  \n",
    "Petal length and width are by far the most important features for classification in the Iris dataset, while sepal length and width contribute much less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8572ba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X_mnist, y_mnist = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "# Train a RandomForestClassifier on a subset for speed\n",
    "rf_mnist = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "rf_mnist.fit(X_mnist[:10000], y_mnist[:10000])\n",
    "\n",
    "# Get feature importances and reshape to 28x28\n",
    "importances = rf_mnist.feature_importances_.reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(importances, cmap='hot', interpolation='nearest')\n",
    "plt.title(\"MNIST Feature Importances (Random Forest)\")\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720ed00",
   "metadata": {},
   "source": [
    "Random Forests are very handy to get a quick understanding of what features\n",
    " actually matter, in particular if you need to perform feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c54d76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35ed243",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     24\u001b[39m voting_clf = VotingClassifier(\n\u001b[32m     25\u001b[39m     estimators=[\n\u001b[32m     26\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m, clf1),\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     voting=\u001b[33m'\u001b[39m\u001b[33mhard\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Use 'soft' if all classifiers support predict_proba\u001b[39;00m\n\u001b[32m     31\u001b[39m )\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Step 4: Use BaggingClassifier on the VotingClassifier\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m bagged_voting = \u001b[43mBaggingClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvoting_clf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     40\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Step 5: Train and evaluate\u001b[39;00m\n\u001b[32m     43\u001b[39m bagged_voting.fit(X_train, y_train)\n",
      "\u001b[31mTypeError\u001b[39m: BaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # For cleaner output\n",
    "\n",
    "# Step 1: Generate synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=20, n_informative=15, n_redundant=5,\n",
    "    random_state=42, class_sep=1.5\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 2: Define individual base models\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = DecisionTreeClassifier()\n",
    "\n",
    "# Step 3: Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', clf1),\n",
    "        ('knn', clf2),\n",
    "        ('dt', clf3)\n",
    "    ],\n",
    "    voting='hard'  # Use 'soft' if all classifiers support predict_proba\n",
    ")\n",
    "\n",
    "# Step 4: Use BaggingClassifier on the VotingClassifier\n",
    "bagged_voting = BaggingClassifier(\n",
    "    base_estimator=voting_clf,\n",
    "    n_estimators=10,\n",
    "    max_samples=0.8,\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 5: Train and evaluate\n",
    "bagged_voting.fit(X_train, y_train)\n",
    "y_pred = bagged_voting.predict(X_test)\n",
    "\n",
    "print(\"Accuracy (Bagged Voting Classifier):\", accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
